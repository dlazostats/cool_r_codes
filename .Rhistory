print(adf_diff2)
ts2_stationary <- diff(ts2)
ts2_is_differenced <- TRUE
} else {
ts2_stationary <- ts2
ts2_is_differenced <- FALSE
}
# Adjust series for equal length if differencing was applied
if(ts1_is_differenced || ts2_is_differenced) {
min_length <- min(length(ts1_stationary), length(ts2_stationary))
ts1_stationary <- ts1_stationary[1:min_length]
ts2_stationary <- ts2_stationary[1:min_length]
}
cat("\n=== CROSS-CORRELATION ANALYSIS ===\n")
# Calculate cross-correlation function
ccf_result <- ccf(ts1_stationary, ts2_stationary,
lag.max = 10, plot = TRUE,
main = "Cross-Correlation Function")
# Extract significant lags
ccf_values <- ccf_result$acf
ccf_lags <- ccf_result$lag
n <- length(ts1_stationary)
critical_value <- 1.96/sqrt(n)
significant_lags <- ccf_lags[abs(ccf_values) > critical_value]
cat("Critical value for 95% confidence:", critical_value, "\n")
cat("Significant cross-correlations at lags:", significant_lags, "\n")
cat("Maximum absolute cross-correlation:", max(abs(ccf_values)), "\n")
cat("\n=== GRANGER CAUSALITY TESTS ===\n")
# Prepare data frame for VAR model
var_data <- data.frame(
prod = ts1_stationary,
refra = ts2_stationary
)
# Determine optimal lag length
lag_selection <- VARselect(var_data, lag.max = 8, type = "const")
cat("Optimal lag selection:\n")
print(lag_selection$selection)
optimal_lag <- lag_selection$selection["AIC(n)"]
# Fit VAR model
var_model <- VAR(var_data, p = optimal_lag, type = "const")
# Granger causality tests
cat("\nGranger Causality Test Results:\n")
granger_prod_to_refra <- causality(var_model, cause = "prod")
granger_refra_to_prod <- causality(var_model, cause = "refra")
cat("Production → Refractory:\n")
print(granger_prod_to_refra$Granger)
cat("\nRefractory → Production:\n")
print(granger_refra_to_prod$Granger)
cat("\n=== ADDITIONAL INDEPENDENCE TESTS ===\n")
# Pearson correlation test
cor_test <- cor.test(ts1_stationary, ts2_stationary)
cat("Pearson Correlation Test:\n")
print(cor_test)
# Spearman correlation test (non-parametric)
spear_test <- cor.test(ts1_stationary, ts2_stationary, method = "spearman")
cat("\nSpearman Correlation Test:\n")
print(spear_test)
# Portmanteau test on cross-correlations
# Using Box-Ljung test on the cross-correlation residuals
ljung_box <- Box.test(ccf_values, lag = 10, type = "Ljung-Box")
cat("\nBox-Ljung test on cross-correlations:\n")
print(ljung_box)
cat("\n" + paste(rep("=", 60), collapse=""))
cat("\n                    INDEPENDENCE TEST SUMMARY")
cat("\n" + paste(rep("=", 60), collapse=""))
cat("\n\n1. STATIONARITY:")
cat(paste("\n   - Cant_prod_tn:", ifelse(ts1_is_differenced, "Non-stationary (differenced)", "Stationary")))
cat(paste("\n   - Cant_refra_kg:", ifelse(ts2_is_differenced, "Non-stationary (differenced)", "Stationary")))
cat("\n\n2. CROSS-CORRELATION:")
cat(paste("\n   - Max absolute cross-correlation:", round(max(abs(ccf_values)), 4)))
cat(paste("\n   - Critical value (95%):", round(critical_value, 4)))
cat(paste("\n   - Significant lags found:", length(significant_lags) > 0))
cat("\n\n3. GRANGER CAUSALITY:")
cat(paste("\n   - Production → Refractory p-value:", round(granger_prod_to_refra$Granger$p.value, 4)))
cat(paste("\n   - Refractory → Production p-value:", round(granger_refra_to_prod$Granger$p.value, 4)))
cat("\n\n4. CORRELATION TESTS:")
cat(paste("\n   - Pearson correlation p-value:", round(cor_test$p.value, 4)))
cat(paste("\n   - Spearman correlation p-value:", round(spear_test$p.value, 4)))
# Independence conclusion
alpha <- 0.05
independence_tests <- c(
granger_prod_to_refra$Granger$p.value > alpha,
granger_refra_to_prod$Granger$p.value > alpha,
cor_test$p.value > alpha,
length(significant_lags) == 0
)
cat("\n\n5. OVERALL CONCLUSION:")
if(all(independence_tests)) {
cat("\n   ✓ EVIDENCE SUPPORTS INDEPENDENCE")
cat("\n   All tests fail to reject independence hypothesis.")
} else {
cat("\n   ✗ EVIDENCE SUGGESTS DEPENDENCE")
cat("\n   Some tests reject independence hypothesis.")
cat("\n   Consider the series as potentially dependent.")
}
cat(paste("\n\n   Note: Tests performed on",
ifelse(ts1_is_differenced || ts2_is_differenced,
"differenced (stationary)", "original"),
"data."))
cat("\n" + paste(rep("=", 60), collapse=""))
# Export results to CSV for further analysis
results_summary <- data.frame(
Test = c("Granger (Prod→Refra)", "Granger (Refra→Prod)",
"Pearson Correlation", "Spearman Correlation",
"Max Cross-Correlation"),
P_Value = c(granger_prod_to_refra$Granger$p.value,
granger_refra_to_prod$Granger$p.value,
cor_test$p.value, spear_test$p.value, NA),
Statistic = c(granger_prod_to_refra$Granger$statistic,
granger_refra_to_prod$Granger$statistic,
cor_test$statistic, spear_test$statistic,
max(abs(ccf_values))),
Significant = c(granger_prod_to_refra$Granger$p.value < alpha,
granger_refra_to_prod$Granger$p.value < alpha,
cor_test$p.value < alpha,
spear_test$p.value < alpha,
max(abs(ccf_values)) > critical_value)
)
write.csv(results_summary, "independence_test_results.csv", row.names = FALSE)
cat("\n\nResults exported to 'independence_test_results.csv'")
# Fit VAR model
var_model <- VAR(var_data, p = optimal_lag, type = "const")
var_model
# Determine optimal lag length
lag_selection <- VARselect(var_data, lag.max = 8, type = "const")
cat("Optimal lag selection:\n")
print(lag_selection$selection)
# Granger causality tests
cat("\nGranger Causality Test Results:\n")
granger_prod_to_refra <- causality(var_model, cause = "prod")
granger_refra_to_prod <- causality(var_model, cause = "refra")
cat("Production → Refractory:\n")
print(granger_prod_to_refra$Granger)
cat("\nRefractory → Production:\n")
print(granger_refra_to_prod$Granger)
var_model
# Calculate cross-correlation function
ccf_result <- ccf(ts1_stationary, ts2_stationary,
lag.max = 10, plot = TRUE,
main = "Cross-Correlation Function")
# Extract significant lags
ccf_values <- ccf_result$acf
ccf_lags <- ccf_result$lag
n <- length(ts1_stationary)
critical_value <- 1.96/sqrt(n)
significant_lags <- ccf_lags[abs(ccf_values) > critical_value]
cat("Critical value for 95% confidence:", critical_value, "\n")
cat("Significant cross-correlations at lags:", significant_lags, "\n")
cat("Maximum absolute cross-correlation:", max(abs(ccf_values)), "\n")
equi_val = {
'CARACTERISTICA': ['QMCR9048', 'QMCR9046', 'QMCR9042','QMCR9036','QMCR9044','QMCR9056','QMCR9266','QMCR9280',
head(mtcars)
scale(mtcars$mpg)
scale(mtcars$mpg)->s1
s1
mean(s1)
sd(s1)
library(dplyr)
library(ggplot2)
library(beta)  # for beta distribution functions
install.packages("beta")
# Set seed for reproducibility
set.seed(123)
# Create simulated baseball data
n_players <- 100
players <- data.frame(
player = paste0("Player_", 1:n_players),
at_bats = sample(50:500, n_players, replace = TRUE)
)
players
# Generate true batting averages from a beta distribution
# Most players have averages around 0.27 with some variation
true_averages <- rbeta(n_players, shape1 = 27, shape2 = 73)
players$true_avg <- true_averages
# Generate observed hits based on true averages
players$hits <- rbinom(n_players, players$at_bats, players$true_avg)
# Calculate naive batting averages (hits/at_bats)
players$naive_avg <- players$hits / players$at_bats
players
overall_mean <- mean(players$naive_avg)
overall_var <- var(players$naive_avg)
# Method of moments estimators for Beta distribution
# Mean = α/(α+β), Variance = αβ/[(α+β)²(α+β+1)]
# Solving these equations:
alpha_mom <- overall_mean * (overall_mean * (1 - overall_mean) / overall_var - 1)
beta_mom <- (1 - overall_mean) * (overall_mean * (1 - overall_mean) / overall_var - 1)
cat("Estimated prior parameters:\n")
cat("α (alpha) =", round(alpha_mom, 2), "\n")
cat("β (beta) =", round(beta_mom, 2), "\n")
cat("Prior mean =", round(alpha_mom / (alpha_mom + beta_mom), 3), "\n")
players$eb_estimate <- (alpha_mom + players$hits) / (alpha_mom + beta_mom + players$at_bats)
# Calculate shrinkage factor for each player
# Shows how much we shrink toward the prior mean
players$shrinkage <- 1 - (players$at_bats / (players$at_bats + alpha_mom + beta_mom))
# Step 3: Evaluate performance
# Calculate Mean Squared Error for both methods
mse_naive <- mean((players$naive_avg - players$true_avg)^2)
mse_eb <- mean((players$eb_estimate - players$true_avg)^2)
cat("\nMean Squared Error comparison:\n")
cat("Naive estimates MSE:", round(mse_naive, 6), "\n")
cat("Empirical Bayes MSE:", round(mse_eb, 6), "\n")
cat("Improvement:", round((mse_naive - mse_eb) / mse_naive * 100, 1), "%\n")
# Plot 1: Naive vs Empirical Bayes estimates
p1 <- ggplot(players, aes(x = naive_avg, y = eb_estimate)) +
geom_point(aes(color = at_bats), alpha = 0.7) +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
scale_color_gradient(low = "lightblue", high = "darkblue", name = "At Bats") +
labs(title = "Empirical Bayes vs Naive Estimates",
subtitle = "Points below diagonal show shrinkage toward prior mean",
x = "Naive Estimate (Hits/At Bats)",
y = "Empirical Bayes Estimate") +
theme_minimal()
print(p1)
# Plot 2: Shrinkage vs Number of At Bats
p2 <- ggplot(players, aes(x = at_bats, y = shrinkage)) +
geom_point(alpha = 0.6, color = "darkgreen") +
geom_smooth(method = "loess", se = TRUE, color = "red") +
labs(title = "Shrinkage Factor vs Sample Size",
subtitle = "More at-bats = less shrinkage toward prior",
x = "Number of At Bats",
y = "Shrinkage Factor") +
theme_minimal()
print(p2)
# Plot 3: Comparison of MSE by at-bats groups
players$at_bats_group <- cut(players$at_bats,
breaks = quantile(players$at_bats, c(0, 0.33, 0.67, 1)),
labels = c("Low", "Medium", "High"),
include.lowest = TRUE)
mse_comparison <- players %>%
group_by(at_bats_group) %>%
summarise(
naive_mse = mean((naive_avg - true_avg)^2),
eb_mse = mean((eb_estimate - true_avg)^2),
improvement = (naive_mse - eb_mse) / naive_mse * 100,
.groups = 'drop'
)
print(mse_comparison)
# Plot 4: Distribution of estimates vs true values
p3 <- players %>%
select(player, true_avg, naive_avg, eb_estimate) %>%
tidyr::pivot_longer(cols = c(naive_avg, eb_estimate),
names_to = "method", values_to = "estimate") %>%
ggplot(aes(x = estimate, fill = method)) +
geom_histogram(alpha = 0.7, bins = 20, position = "identity") +
geom_vline(xintercept = mean(players$true_avg), linetype = "dashed",
color = "black", size = 1) +
labs(title = "Distribution of Estimates vs True Averages",
subtitle = "Vertical line shows true population mean",
x = "Batting Average", y = "Count") +
scale_fill_manual(values = c("eb_estimate" = "blue", "naive_avg" = "red"),
labels = c("Empirical Bayes", "Naive"),
name = "Method") +
theme_minimal()
print(p3)
# Example of credible intervals for a few players
# Select players with different sample sizes
example_players <- players %>%
arrange(at_bats) %>%
slice(c(1, 25, 50, 75, 100))  # Low to high at-bats
cat("\nCredible Intervals (95%) for Selected Players:\n")
cat("Player\t\tAt Bats\tHits\tNaive\tEB Est\t95% Credible Interval\n")
cat("------\t\t-------\t----\t-----\t------\t-------------------\n")
for(i in 1:nrow(example_players)) {
player_data <- example_players[i, ]
# Posterior parameters
post_alpha <- alpha_mom + player_data$hits
post_beta <- beta_mom + player_data$at_bats - player_data$hits
# 95% credible interval
ci_lower <- qbeta(0.025, post_alpha, post_beta)
ci_upper <- qbeta(0.975, post_alpha, post_beta)
cat(sprintf("%s\t%d\t%d\t%.3f\t%.3f\t[%.3f, %.3f]\n",
player_data$player, player_data$at_bats, player_data$hits,
player_data$naive_avg, player_data$eb_estimate,
ci_lower, ci_upper))
}
cat("\nKey Insights:\n")
cat("1. Empirical Bayes shrinks extreme estimates toward the overall mean\n")
cat("2. Players with fewer at-bats are shrunk more heavily\n")
cat("3. The method reduces overall prediction error\n")
cat("4. Provides natural uncertainty quantification via credible intervals\n")
# Ridge Regression
#------------------
library(dplyr)
getwd()
# set working directory
setwd("C:/Users/dlazo/OneDrive - CORPORACIÓN ACEROS AREQUIPA SA/Escritorio/Diego/cool_r_codes")
# load data
db_dib0<-read.csv("diabetes.csv")
# load data
db_dib0<-read.csv("diabetes.csv")
# load data
db_dib0<-read.csv("diabetes.csv")
db_dib0
# load data
db_dib0<-read.csv("diabetes.csv")
head(db_dib0)
# Eda
hist(db_dib0$prog,breaks="FD")
# Eda
hist(db_dib0$prog)
# Eda
hist(db_dib0$prog,breaks="FD")
hist(db_dib0$prog,breaks=40)
hist(db_dib0$prog,breaks="Scott")
# Eda
hist(db_dib0$prog,breaks="FD")
hist(db_dib0$prog,breaks="Scott")
hist(db_dib0$prog,breaks="FD")
hist(db_dib0$prog,breaks=30)
library(ggplot2)
ggplot(db_dib0,aes(x=prog))+
geom_histogram()
ggplot(db_dib0,aes(x=prog))+
geom_histogram(color="black",fill="white")
library(lattice)
histogram(mpg|data=db_dib0,type="denisty")
?histogram
histogram(prog|data=db_dib0,type="denisty")
histogram(~prog|prog,data=db_dib0,type="denisty")
library(MASS)
truehist(db_dib0$prog, nbins = 20, col = "lightgray")
library(Hmisc)
histogram(~ prog, data = db_dib0)
truehist(db_dib0$prog, nbins = 20, col = "lightgray")
histogram(~ prog, data = db_dib0)
library(psych)
pairs.panels(db_dib0)
pairs.panels(db_dib0 %>% dplyr::select(-sex))
pairs.panels(db_dib0 %>% dplyr::select(-sex,prog,everything()))
pairs.panels(db_dib0 %>% dplyr::select(prog,everything()))
pairs.panels(db_dib0 %>% dplyr::select(prog,everything(),-sex))
# linear regression
lm_mdl1<-lm(prog~.,data=db_dib0)
library(broom)
library(jtools)
summ(lm_mdl1)
dim(db_dib0)
library(caret)
?train
lm<-train(prog~.,
data=db_dib0,
method="lm",
preProcess = "scale")
summ(lm$finalModel)
dim(db_dib0)
lm<-train(prog~ -1,
data=db_dib0,
method="lm",
preProcess = "scale")
lm<-train(prog~ -1+.,
data=db_dib0,
method="lm",
preProcess = "scale")
summ(lm$finalModel)
# linear regression
lm_mdl1<-lm(prog~.,data=db_dib0)
summ(lm_mdl1)
# linear regression
lm_mdl1<-lm(prog~-<+.,data=db_dib0)
# linear regression
lm_mdl1<-lm(prog~-1+.,data=db_dib0)
summ(lm_mdl1)
m1<-lm_mdl1 %>% select(-prog) %>% as.matrix()
m1<-lm_mdl1 %>% dplyr::select(-prog) %>% as.matrix()
m1<-db_dib0 %>% dplyr::select(-prog) %>% as.matrix()
m1
dim(m1)
# linear regression
lm_mdl1<-lm(prog~-1+.,data=db_dib0)
summ(lm_mdl1)
db_dib0
summ(lm_mdl1)
# linear regression
lm_mdl1<-lm(prog~scale(.),data=db_dib0)
# linear regression
X_scaled <- scale(db_dib0[ , !(names(db_dib0) == "prog") ])
lm_mdl1<-lm(prog~.,data=X_scaled)
# linear regression
X_scaled <- scale(db_dib0[ , !(names(db_dib0) == "prog") ]) %>% as.data.frame()
X_scaled
lm_mdl1<-lm(db_dib0$prog~.,data=X_scaled)
summ(lm_mdl1)
#processing
db_dib1<-db_dib0 %>%
mutate(prog=prog-mean(prog)) %>%
mutate(across(.cols = -prog, .fns = scale))
# linear regression
lm_mdl1<-lm(prog~.,data=db_dib1)
summ(lm_mdl1)
#processing
db_dib1<-db_dib0 %>%
mutate(prog=prog-mean(prog)) %>%
mutate(across(.cols = -prog, .fns = scale))
head(db_dib0)
head(db_dib1)
#processing
db_dib1<-db_dib0 %>%
mutate(prog=prog-mean(prog)) %>%
mutate(across(.cols = -prog, .fns = scale))
# linear regression
lm_mdl1<-lm(prog~.,data=db_dib1)
summ(lm_mdl1)
# linear regression
lm_mdl1<-lm(prog~.,data=db_dib0)
summ(lm_mdl1)
X <- scale(db_dib0[ , predictors])
y <- db_dib0$prog - mean(db_dib0$prog)
X <- scale(db_dib0[ , !(names(db_dib0) == "prog") ])
y <- db_dib0$prog - mean(db_dib0$prog)
X
X <- scale(db_dib0[ , !(names(db_dib0) == "prog") ])
y <- db_dib0$prog - mean(db_dib0$prog)
l1<-lm(y~X)
summary(l<)
summary(l1)
min_max <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
#processing
db_dib1<-db_dib0 %>%
mutate(prog=prog-mean(prog)) %>%
mutate(across(.cols = -prog, .fns = min_max))
# linear regression
lm_mdl1<-lm(prog~.,data=db_dib0)
summ(lm_mdl1)
X <- min_max(db_dib0[ , !(names(db_dib0) == "prog") ])
X
y <- db_dib0$prog - mean(db_dib0$prog)
l1<-lm(y~X)
db_dib0
X <- min_max(db_dib0[ , !(names(db_dib0) == "prog") ])
y <- db_dib0$prog - mean(db_dib0$prog)
l1<-lm(y~X)
X <- min_max(db_dib0[ , !(names(db_dib0) == "prog") ]) %>% as.data.frame()
y <- db_dib0$prog - mean(db_dib0$prog)
l1<-lm(y~X)
Xs<-db_dib0 %>% select(-prog)
Xs<-db_dib0 %>% dplyr::select(-prog)
Xs<-sapply(Xs,min_max)
y <- db_dib0$prog - mean(db_dib0$prog)
l1<-lm(y~X)
l1<-lm(y~Xs)
summary(l1)
?train
X <- model.matrix(prog ~ ., db_dib0)[ , -1]  # Removes intercept column
y <- db_dib0$prog
ridge_model <- glmnet(X, y, alpha = 0.1)
summary(ridge_model)
coef(ridge_model)
coef(ridge_model,s=lambda_seg[1])
coef(ridge_model,s=lamda_seq[1])
ridge_model$lambda
coef(ridge_model,s=ridge_model$lambda[91])
library(glmnet)  # for ridge regression
library(readr)   # for reading CSV
# Read the diabetes dataset
diabetes <- read_csv("diabetes.csv")
# Remove the index column (first column with empty name)
diabetes <- diabetes[, -1]
# Prepare the data
# X matrix (predictors) - all columns except 'prog'
X <- as.matrix(diabetes[, c("age", "sex", "bmi", "map", "tc", "ldl", "hdl", "tch", "ltg", "glu")])
diabetes
# Read the diabetes dataset
diabetes <- read_csv("diabetes.csv")
diabetes
# Prepare the data
# X matrix (predictors) - all columns except 'prog'
X <- as.matrix(diabetes[, c("age", "sex", "bmi", "map", "tc", "ldl", "hdl", "tch", "ltg", "glu")])
# y vector (response variable)
y <- diabetes$prog
# 1. Ordinary Least Squares (OLS) regression
ols_model <- lm(prog ~ age + sex + bmi + map + tc + ldl + hdl + tch + ltg + glu, data = diabetes)
# Extract OLS coefficients (excluding intercept)
ols_coef <- coef(ols_model)[-1]  # Remove intercept
ols_coef
# Extract OLS standard errors (excluding intercept)
ols_se <- summary(ols_model)$coefficients[-1, "Std. Error"]
ols_se
# y vector (response variable)
y <- diabetes$prog-mean(diabetes$prog)
Xs<-sapply(X,scale)
# y vector (response variable)
y <- diabetes$prog-mean(diabetes$prog)
dt<-data.frame(prog=y) %>% rbind(Xs)
dt<-data.frame(prog=y) %>% cbind(Xs)
dt
Xs<-sapply(X,scale) %>% as.data.frame()
# y vector (response variable)
y <- diabetes$prog-mean(diabetes$prog)
dt<-data.frame(prog=y) %>% cbind(Xs)
dt
Xs
Xs<-sapply(X,scale)
Xs
# Prepare the data
# X matrix (predictors) - all columns except 'prog'
X <- as.matrix(diabetes[, c("age", "sex", "bmi", "map", "tc", "ldl", "hdl", "tch", "ltg", "glu")])
X
Xs<-sapply(X %>% as.data.frame,scale)
Xs
# y vector (response variable)
y <- diabetes$prog-mean(diabetes$prog)
dt<-data.frame(prog=y) %>% cbind(Xs)
dt
# 1. Ordinary Least Squares (OLS) regression
ols_model <- lm(prog ~ age + sex + bmi + map + tc + ldl + hdl + tch + ltg + glu, data = dt)
# Extract OLS coefficients (excluding intercept)
ols_coef <- coef(ols_model)[-1]  # Remove intercept
# Extract OLS standard errors (excluding intercept)
ols_se <- summary(ols_model)$coefficients[-1, "Std. Error"]
ols_coef
